name: Cross-Reference Validation CI

on:
  pull_request:
    branches:
      - master
      - main
    paths:
      - 'scripts/**'
      - 'validation/**'
      - 'tests/**'
      - 'config/**'
  push:
    branches:
      - master
      - main
  workflow_dispatch:

jobs:
  placeholder-check:
    name: Validate CSV Provenance (No REPLACE_ME)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Check for placeholder values
        run: |
          cd validation
          files=""
          test -f gold_set.csv && files="$files gold_set.csv" || true
          test -f negative_controls.csv && files="$files negative_controls.csv" || true

          if [ -n "$files" ]; then
            echo "Checking files: $files"
            if grep -Hn "REPLACE_ME" $files; then
              echo "::error::Found placeholder 'REPLACE_ME' in one or more CSVs."
              echo "::error::Replace with real, verified values before merging."
              exit 1
            fi
            echo "✅ No placeholders found - all CSVs have real data"
          else
            echo "⚠️  No CSV files found in validation/ - using starter files for CI test"
          fi

  schema-validation:
    name: JSON Schema Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install jsonschema pytest

      - name: Validate entity schema
        run: |
          python -c "
          import json
          from jsonschema import validate, Draft7Validator

          # Load schema
          with open('config/entity_schema.json', 'r') as f:
              schema = json.load(f)

          # Validate schema itself
          Draft7Validator.check_schema(schema)
          print('✅ Entity schema is valid JSON Schema Draft 7')
          "

      - name: Validate detection schema
        run: |
          python -c "
          import json
          from jsonschema import validate, Draft7Validator

          # Load schema
          with open('config/detection_schema.json', 'r') as f:
              schema = json.load(f)

          # Validate schema itself
          Draft7Validator.check_schema(schema)
          print('✅ Detection schema is valid JSON Schema Draft 7')
          "

  provenance-check:
    name: Provenance Completeness Check
    runs-on: ubuntu-latest
    needs: schema-validation
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install pandas jsonschema

      - name: Check gold set provenance
        run: |
          python -c "
          import pandas as pd
          import sys

          # Load gold set (use starter if main not exists)
          try:
              df = pd.read_csv('validation/gold_set.csv')
          except FileNotFoundError:
              df = pd.read_csv('validation/gold_set_starter.csv')
              print('ℹ️  Using starter gold set for CI validation')

          # Check required fields
          required = ['canonical_name', 'label', 'provenance__primary_source', 'reviewer']
          missing = [col for col in required if col not in df.columns]

          if missing:
              print(f'❌ Missing required columns: {missing}')
              sys.exit(1)

          # Check no empty provenance
          empty_prov = df[df['provenance__primary_source'].isna() | (df['provenance__primary_source'] == '')]
          if len(empty_prov) > 0:
              print(f'❌ {len(empty_prov)} entities missing primary provenance')
              print(empty_prov[['canonical_name', 'label']])
              sys.exit(1)

          print(f'✅ All {len(df)} gold set entities have complete provenance')
          "

      - name: Check negative controls provenance
        run: |
          python -c "
          import pandas as pd
          import sys

          # Load negative controls (use starter if main not exists)
          try:
              df = pd.read_csv('validation/negative_controls.csv')
          except FileNotFoundError:
              df = pd.read_csv('validation/negative_controls_starter.csv')
              print('ℹ️  Using starter negative controls for CI validation')

          # Check required fields
          required = ['canonical_name', 'reason_clean', 'provenance__clean_sources']
          missing = [col for col in required if col not in df.columns]

          if missing:
              print(f'❌ Missing required columns: {missing}')
              sys.exit(1)

          # Check no empty provenance
          empty_prov = df[df['provenance__clean_sources'].isna() | (df['provenance__clean_sources'] == '')]
          if len(empty_prov) > 0:
              print(f'❌ {len(empty_prov)} entities missing clean provenance')
              print(empty_prov[['canonical_name']])
              sys.exit(1)

          print(f'✅ All {len(df)} negative controls have clean provenance')
          "

  pytest-validation:
    name: Pytest Validation Suite
    runs-on: ubuntu-latest
    needs: [schema-validation, provenance-check]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install pytest pytest-html jsonschema pandas scikit-learn

      - name: Create test entities.ndjson (if not exists)
        run: |
          # Create minimal test output for CI if no real output exists
          if [ ! -f entities.ndjson ]; then
            echo 'Creating test entities.ndjson for CI validation'
            cat > entities.ndjson << 'EOF'
          {"run_id":"ci_test_run","entity_id":"test_001","canonical_name":"Test Entity 1","entity_type":"company","country_iso3":"GBR","china_connections":[],"aggregate_risk":{"posterior_probability":0.01,"risk_score":1,"risk_level":"LOW"},"detector_versions":{"test":"v1.0"},"incomplete_fields":[]}
          {"run_id":"ci_test_run","entity_id":"test_002","canonical_name":"Huawei Technologies Co Ltd","entity_type":"company","country_iso3":"CHN","china_connections":[{"detection_id":"det_001","detector_id":"test_detector_v1.0","confidence_score":95,"evidence":{"file_id_or_url":"test_data.csv","record_id_or_line":"line_1","field_name":"nationality","field_value":"Chinese"},"temporal_range":{"valid_from":"2020-01-01","valid_to":"2025-12-31","inferred":false}}],"aggregate_risk":{"posterior_probability":0.95,"risk_score":95,"risk_level":"CRITICAL"},"detector_versions":{"test":"v1.0"},"incomplete_fields":[]}
          EOF
          fi

      - name: Run pytest validation suite
        run: |
          set -e
          mkdir -p test-results

          # Run pytest with coverage and junit XML output
          pytest tests/ \
            -v \
            --maxfail=5 \
            --disable-warnings \
            --junitxml=test-results/junit.xml \
            --html=test-results/pytest_report.html \
            --self-contained-html \
            || echo "::warning::Some pytest tests failed - check report"

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: test-results/
          retention-days: 30

  detector-correlation-check:
    name: Detector Independence Check
    runs-on: ubuntu-latest
    needs: pytest-validation
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install pandas numpy scikit-learn

      - name: Check detector correlation matrix
        run: |
          python -c "
          import sys
          from pathlib import Path

          corr_file = Path('data/processed/detector_correlation_matrix.csv')

          if not corr_file.exists():
              print('⚠️  Detector correlation matrix not yet computed - skipping check')
              sys.exit(0)

          import pandas as pd

          df = pd.read_csv(corr_file, index_col=0)

          # Check for high correlation (>0.8) between detectors
          high_corr = []
          for i in range(len(df.columns)):
              for j in range(i+1, len(df.columns)):
                  corr = df.iloc[i, j]
                  if abs(corr) > 0.8:
                      high_corr.append((df.columns[i], df.columns[j], corr))

          if high_corr:
              print('⚠️  High correlation detected between detectors:')
              for det_a, det_b, corr in high_corr:
                  print(f'  {det_a} ↔ {det_b}: {corr:.2f}')
              print('Ensure Bayesian fusion applies correlation-based shrinkage')
          else:
              print('✅ No excessive detector correlation detected')
          "

  psc-reconciliation-check:
    name: PSC Reconciliation Note Check
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Check reconciliation note exists
        run: |
          if [ -f reconciliation_note.md ]; then
            echo "✅ PSC reconciliation note found"

            # Check it explains v1.0 -> v2.0 difference
            if grep -q "1.13" reconciliation_note.md && grep -q "strict" reconciliation_note.md; then
              echo "✅ Reconciliation note mentions v1.0 (1.13M) and strict detection"
            else
              echo "⚠️  Reconciliation note should explain v1.0 → v2.0 difference"
            fi
          else
            echo "ℹ️  PSC reconciliation note not yet created (will be generated in Phase 1)"
          fi

  security-check:
    name: Security & Secrets Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Check for exposed secrets
        run: |
          # Check for common secret patterns
          echo "Scanning for potential secrets..."

          # API keys
          if git grep -E "(api[_-]?key|apikey|api[_-]?secret)" -- '*.py' '*.json' '*.yaml' '*.yml' | grep -v "# "; then
            echo "::error::Found potential API key references - ensure they use environment variables"
            exit 1
          fi

          # Database passwords
          if git grep -E "(password|passwd|pwd)\s*=\s*['\"]" -- '*.py' '*.json' '*.yaml' '*.yml'; then
            echo "::error::Found hardcoded passwords - use environment variables"
            exit 1
          fi

          echo "✅ No obvious secrets detected"

      - name: Check sensitive data handling
        run: |
          # Ensure PSC data isn't committed
          if [ -f "F:/OSINT_DATA/CompaniesHouse_UK/raw/psc-snapshot-*.txt" ]; then
            echo "::error::PSC snapshot should not be committed to repo"
            exit 1
          fi

          # Check .gitignore includes sensitive paths
          if [ -f .gitignore ]; then
            if grep -q "data/processed" .gitignore && grep -q "*.db" .gitignore; then
              echo "✅ .gitignore properly excludes processed data"
            else
              echo "::warning::.gitignore should exclude data/processed and *.db files"
            fi
          fi

  documentation-check:
    name: Documentation Completeness
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Check required documentation
        run: |
          docs=(
            "CROSS_REFERENCE_ANALYSIS_MASTER_PLAN.md"
            "CROSS_REFERENCE_RED_TEAM_ENHANCEMENTS_v2.md"
            "VALIDATION_FRAMEWORK.md"
            "IMPLEMENTATION_ROADMAP_v2.md"
          )

          missing=()
          for doc in "${docs[@]}"; do
            if [ ! -f "$doc" ]; then
              missing+=("$doc")
            fi
          done

          if [ ${#missing[@]} -gt 0 ]; then
            echo "::error::Missing documentation: ${missing[*]}"
            exit 1
          fi

          echo "✅ All required documentation present"

      - name: Check README has usage instructions
        run: |
          if [ -f README.md ]; then
            if grep -q "validation" README.md && grep -q "pytest" README.md; then
              echo "✅ README includes validation instructions"
            else
              echo "::warning::README should document validation and testing process"
            fi
          fi

  summary:
    name: CI Summary
    runs-on: ubuntu-latest
    needs: [placeholder-check, schema-validation, provenance-check, pytest-validation, security-check, documentation-check]
    if: always()
    steps:
      - name: Check all jobs passed
        run: |
          echo "## Cross-Reference Validation CI Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check job results
          if [ "${{ needs.placeholder-check.result }}" == "success" ] && \
             [ "${{ needs.schema-validation.result }}" == "success" ] && \
             [ "${{ needs.provenance-check.result }}" == "success" ] && \
             [ "${{ needs.pytest-validation.result }}" == "success" ] && \
             [ "${{ needs.security-check.result }}" == "success" ] && \
             [ "${{ needs.documentation-check.result }}" == "success" ]; then
            echo "✅ All validation checks passed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Safe to merge** - all anti-fabrication, provenance, and security checks passed." >> $GITHUB_STEP_SUMMARY
            exit 0
          else
            echo "❌ Some validation checks failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Review required** - check failed jobs above." >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
