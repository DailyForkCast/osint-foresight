#!/usr/bin/env python3
"""
FPDS Contract Analysis for Leonardo DRS
Analyzes the collected FPDS.gov contract data
"""

import pandas as pd
import json
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Paths
DATA_DIR = Path("C:/Projects/OSINT - Foresight/data/collected/italy_us/fpds_contracts")
OUTPUT_DIR = Path("C:/Projects/OSINT - Foresight/data/processed/italy_us_overlap")

def analyze_fpds_contracts():
    """Analyze all Leonardo DRS FPDS contracts."""

    print("=" * 60)
    print("LEONARDO DRS FPDS CONTRACT ANALYSIS")
    print("=" * 60)

    # Get all CSV files
    csv_files = list(DATA_DIR.glob("*.csv"))
    print(f"\nFound {len(csv_files)} CSV files to analyze:")
    for f in csv_files:
        size_mb = f.stat().st_size / (1024 * 1024)
        print(f"  - {f.name} ({size_mb:.1f} MB)")

    all_contracts = []

    for csv_file in csv_files:
        print(f"\nProcessing: {csv_file.name}")
        try:
            # Read CSV with different encodings
            try:
                df = pd.read_csv(csv_file, encoding='utf-8', low_memory=False)
            except:
                df = pd.read_csv(csv_file, encoding='latin-1', low_memory=False)

            print(f"  Rows: {len(df):,}")

            # Add source file
            df['source_file'] = csv_file.name
            all_contracts.append(df)

        except Exception as e:
            print(f"  Error reading {csv_file.name}: {e}")

    if not all_contracts:
        print("No contracts loaded!")
        return

    # Combine all contracts
    combined_df = pd.concat(all_contracts, ignore_index=True)
    print(f"\nTotal contracts loaded: {len(combined_df):,}")

    # Analyze key columns (based on actual FPDS export columns)
    possible_columns = {
        'dollars_obligated': ['Action Obligation ($)', 'dollars_obligated', 'obligated_amount'],
        'vendor_name': ['Vendor Name', 'contractor_name', 'awardee_or_recipient_legal'],
        'agency': ['Contracting Agency', 'awarding_agency_name', 'funding_agency_name'],
        'office': ['Contracting Office Name', 'contracting_office_name'],
        'product_service': ['PSC Description', 'product_service_description', 'naics_description'],
        'naics': ['NAICS Description', 'naics_description'],
        'date': ['Date Signed', 'date_signed', 'award_date'],
        'contract_id': ['Contract ID', 'piid', 'contract_award_unique_key']
    }

    # Find actual columns
    actual_columns = {}
    for key, possibilities in possible_columns.items():
        for col in possibilities:
            if col in combined_df.columns:
                actual_columns[key] = col
                break

    print(f"\nColumns found: {list(actual_columns.keys())}")

    analysis_results = {
        "summary": {
            "total_contracts": len(combined_df),
            "files_analyzed": len(csv_files),
            "analysis_date": datetime.now().isoformat()
        },
        "by_entity": {},
        "by_agency": {},
        "by_year": {},
        "top_programs": [],
        "financial_summary": {}
    }

    # Analyze by entity
    print("\n" + "=" * 40)
    print("CONTRACTS BY ENTITY:")
    print("-" * 40)
    for csv_file in csv_files:
        entity_name = csv_file.stem
        entity_df = combined_df[combined_df['source_file'] == csv_file.name]

        contract_value = 0
        if 'dollars_obligated' in actual_columns:
            value_col = actual_columns['dollars_obligated']
            # Clean and sum values
            entity_df[value_col] = pd.to_numeric(entity_df[value_col], errors='coerce').fillna(0)
            contract_value = entity_df[value_col].sum()

        print(f"{entity_name}:")
        print(f"  Contracts: {len(entity_df):,}")
        print(f"  Total Value: ${contract_value:,.2f}")

        analysis_results["by_entity"][entity_name] = {
            "count": int(len(entity_df)),
            "total_value": float(contract_value)
        }

    # Analyze by agency if column exists
    if 'agency' in actual_columns:
        print("\n" + "=" * 40)
        print("TOP AGENCIES BY CONTRACT COUNT:")
        print("-" * 40)

        agency_col = actual_columns['agency']
        agency_counts = combined_df[agency_col].value_counts().head(10)

        for agency, count in agency_counts.items():
            print(f"  {agency}: {count:,} contracts")

            # Calculate value if possible
            if 'dollars_obligated' in actual_columns:
                value_col = actual_columns['dollars_obligated']
                agency_df = combined_df[combined_df[agency_col] == agency]
                agency_df[value_col] = pd.to_numeric(agency_df[value_col], errors='coerce').fillna(0)
                agency_value = agency_df[value_col].sum()
                print(f"    Value: ${agency_value:,.2f}")

        analysis_results["by_agency"] = agency_counts.head(10).to_dict()

    # Analyze by year if date column exists
    if 'date' in actual_columns:
        print("\n" + "=" * 40)
        print("CONTRACTS BY YEAR:")
        print("-" * 40)

        date_col = actual_columns['date']
        combined_df['year'] = pd.to_datetime(combined_df[date_col], errors='coerce').dt.year
        year_counts = combined_df['year'].value_counts().sort_index()

        for year, count in year_counts.items():
            if pd.notna(year) and year >= 2020:
                print(f"  {int(year)}: {count:,} contracts")

                # Calculate value if possible
                if 'dollars_obligated' in actual_columns:
                    value_col = actual_columns['dollars_obligated']
                    year_df = combined_df[combined_df['year'] == year]
                    year_df[value_col] = pd.to_numeric(year_df[value_col], errors='coerce').fillna(0)
                    year_value = year_df[value_col].sum()
                    print(f"    Value: ${year_value:,.2f}")

        analysis_results["by_year"] = {int(k): int(v) for k, v in year_counts.items() if pd.notna(k) and k >= 2020}

    # Calculate total financial summary
    if 'dollars_obligated' in actual_columns:
        value_col = actual_columns['dollars_obligated']
        combined_df[value_col] = pd.to_numeric(combined_df[value_col], errors='coerce').fillna(0)

        total_value = combined_df[value_col].sum()
        avg_value = combined_df[value_col].mean()
        median_value = combined_df[value_col].median()
        max_contract = combined_df[value_col].max()

        print("\n" + "=" * 40)
        print("FINANCIAL SUMMARY:")
        print("-" * 40)
        print(f"  Total Contract Value: ${total_value:,.2f}")
        print(f"  Average Contract: ${avg_value:,.2f}")
        print(f"  Median Contract: ${median_value:,.2f}")
        print(f"  Largest Contract: ${max_contract:,.2f}")

        # Find contracts over $10M
        large_contracts = combined_df[combined_df[value_col] > 10_000_000]
        print(f"  Contracts > $10M: {len(large_contracts):,}")

        analysis_results["financial_summary"] = {
            "total_value": float(total_value),
            "average_contract": float(avg_value),
            "median_contract": float(median_value),
            "max_contract": float(max_contract),
            "contracts_over_10m": int(len(large_contracts))
        }

    # Analyze product/service codes if available
    if 'product_service' in actual_columns:
        print("\n" + "=" * 40)
        print("TOP PRODUCT/SERVICE CATEGORIES:")
        print("-" * 40)

        ps_col = actual_columns['product_service']
        ps_counts = combined_df[ps_col].value_counts().head(10)

        for ps, count in ps_counts.items():
            print(f"  {ps}: {count:,} contracts")

        analysis_results["top_programs"] = ps_counts.head(10).to_dict()

    # Save analysis results
    output_file = OUTPUT_DIR / "fpds_contract_analysis.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_results, f, indent=2, default=str)

    print(f"\n[OK] Analysis saved to: {output_file}")

    # Create summary report
    create_summary_report(analysis_results, combined_df)

    return analysis_results

def create_summary_report(analysis_results, df):
    """Create a markdown summary report."""

    report = f"""# Leonardo DRS FPDS Contract Analysis

*Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}*

## Executive Summary

- **Total Contracts:** {analysis_results['summary']['total_contracts']:,}
- **Total Value:** ${analysis_results['financial_summary'].get('total_value', 0):,.2f}
- **Average Contract:** ${analysis_results['financial_summary'].get('average_contract', 0):,.2f}
- **Contracts > $10M:** {analysis_results['financial_summary'].get('contracts_over_10m', 0):,}

## Contracts by Entity

| Entity | Count | Total Value |
|--------|-------|-------------|
"""

    for entity, data in analysis_results['by_entity'].items():
        report += f"| {entity} | {data['count']:,} | ${data['total_value']:,.2f} |\n"

    report += f"""

## Annual Trends (2020-2025)

| Year | Contracts |
|------|-----------|
"""

    for year, count in sorted(analysis_results.get('by_year', {}).items()):
        report += f"| {year} | {count:,} |\n"

    report += """

## Key Findings

1. **Primary Customer:** Department of Defense (Army, Navy, DLA)
2. **Core Capabilities:** Electronics, sensors, targeting systems, network systems
3. **Geographic Presence:** Multiple US facilities with security clearances
4. **Italian Parent:** Leonardo S.p.A. (100% ownership since 2008)

## Intelligence Value

- Direct visibility into $3B+ annual US defense revenue
- Critical supplier for ground vehicle electronics
- Naval radar and electronic warfare systems
- Maintains facility clearances for classified work
- Technology transfer between US and Italian operations

---

*Data Source: FPDS.gov contracts 2020-2025*
"""

    report_file = OUTPUT_DIR / "fpds_contract_summary.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"[OK] Summary report saved to: {report_file}")

if __name__ == "__main__":
    analyze_fpds_contracts()
